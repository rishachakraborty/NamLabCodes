{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "098eaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstimcells(xmlfilepoints,opsdict,envfileforz,envfileforpoints):\n",
    "    stimcelldict = {}\n",
    "    for i in range(len(xmlfilepoints)):\n",
    "        xpix = opsdict['Lx'] * xmlfilepoints['X'][i]\n",
    "        ypix = opsdict['Ly'] * xmlfilepoints['Y'][i]\n",
    "        index = xmlfilepoints['Index'][i]\n",
    "        for j in range(len(envfileforpoints['Indices'])):\n",
    "            if type(envfileforpoints['Indices'][j]) == str:\n",
    "                if \" \" not in envfileforpoints['Indices'][j]:\n",
    "                    if int(envfileforpoints['Indices'][j]) == int(index):\n",
    "                        point = envfileforpoints['Points'][j]\n",
    "                    for k in range(len(envfileforz['Name'])):\n",
    "                        if envfileforz['Name'][k] == point:\n",
    "                            z = envfileforz['Z'][k]\n",
    "                            stimcelldict[i] = [index, ypix, xpix, z]\n",
    "            if type(envfileforpoints['Indices'][j]) == np.float64:\n",
    "                if np.isnan(envfileforpoints['Indices'][j]) == False:\n",
    "                    if int(envfileforpoints['Indices'][j]) == int(index):\n",
    "                        point = envfileforpoints['Points'][j]\n",
    "                    for k in range(len(envfileforz['Name'])):\n",
    "                        if envfileforz['Name'][k] == point:\n",
    "                            z = envfileforz['Z'][k]\n",
    "                            stimcelldict[i] = [index, ypix, xpix, z]\n",
    "    stimcelldf = ((pd.DataFrame.from_dict(stimcelldict, orient='index')).drop_duplicates()).transpose()\n",
    "    \n",
    "    return stimcelldf\n",
    "    \n",
    "def getdicts(directory, reference_plane):\n",
    "    files = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(directory)\n",
    "             for name in files if os.path.splitext(name)[-1] in '.xml']\n",
    "    sub = \"MarkPoints\"\n",
    "    for i,file in enumerate(files):\n",
    "        if sub in file:\n",
    "            stimtimedict, numiter, numstim = gettimedict(file)\n",
    "            xmlfilepoints = pd.read_xml(file, xpath='.//Point')\n",
    "        elif '.xml' in file:\n",
    "            xmlfiletime = pd.read_xml(file,xpath='.//Frame')     \n",
    "            \n",
    "    filesenv = [os.path.join(root, name)\n",
    "                for root, dirs, files in os.walk(directory)\n",
    "                for name in files if os.path.splitext(name)[-1] in '.env']\n",
    "    for i, file in enumerate(filesenv):\n",
    "        if '.env' in file:\n",
    "            envfileforz = pd.read_xml(file, xpath='.//PVGalvoPoint')\n",
    "            envfileforpoints = pd.read_xml(file, xpath='.//PVGalvoPointElement')\n",
    "            \n",
    "    directory = directory + 'suite2p'\n",
    "    sub = \"plane\"\n",
    "    databindict = {}\n",
    "    for i, file in enumerate(os.listdir(directory)):\n",
    "        if sub in file:\n",
    "            if file == (sub + str(reference_plane)):\n",
    "                statdictall = np.load(directory + '/' + file + '/stat.npy', allow_pickle = True)\n",
    "                fluoresencedict = np.load(directory + '/' + file + '/F.npy', allow_pickle = True)\n",
    "                neuropildict = np.load(directory + '/' + file + '/Fneu.npy', allow_pickle = True)\n",
    "                spikesdict = np.load(directory + '/' + file + '/spks.npy', allow_pickle = True)\n",
    "                opsdict = ((np.load(directory + '/' + file + '/ops.npy', allow_pickle = True)).reshape(1,))[0]\n",
    "                iscelldict = np.sum((np.load(directory + '/' + file + '/iscell.npy', allow_pickle = True)).astype(int), axis =1)\n",
    "                statdict = statdictall[np.where(iscelldict>=1)]\n",
    "                fluoresencedict = fluoresencedict[np.where(iscelldict>=1)]\n",
    "                neuropildict = neuropildict[np.where(iscelldict>=1)]\n",
    "                spikesdict = spikesdict[np.where(iscelldict>=1)]\n",
    "                databindict[int(file.replace(sub, ''))] = directory + '/' + file + '/data.bin'\n",
    "            else:\n",
    "                databindict[int(file.replace(sub, ''))] = directory + '/' + file + '/data.bin'\n",
    "        \n",
    "    stimcelldf = getstimcells(xmlfilepoints,opsdict,envfileforz,envfileforpoints)\n",
    "    ROIdict = roidict(statdict)\n",
    "    \n",
    "    return stimtimedict, numiter, numstim, xmlfiletime, fluoresencedict, neuropildict, spikesdict, opsdict, databindict, statdict, stimcelldf, ROIdict\n",
    "\n",
    "\n",
    "def gettrace(ROIindex, fluoresencedict, opsdict, neuropildict):\n",
    "    return fluoresencedict[ROIindex] - opsdict['neucoeff']*neuropildict[ROIindex]\n",
    "\n",
    "def roidict(statdict):\n",
    "    ROIdict = {}\n",
    "    for i in range(len(statdict)):\n",
    "        ROIdict[i] = statdict[i]['med']\n",
    "    return ROIdict\n",
    "\n",
    "def getframetimes(framearray,planeofinterest,numplanes):\n",
    "    timearray = []\n",
    "    for i in range(int(len(framearray)/numplanes)):\n",
    "        timearray = np.append(timearray,framearray[numplanes*i + planeofinterest])\n",
    "    return timearray\n",
    "\n",
    "\n",
    "def closestframe(time, timearray):\n",
    "    timearray = [frame - time for frame in timearray]\n",
    "    return np.argmin(np.absolute(timearray))\n",
    "\n",
    "\n",
    "def closestROI(XYPoint,ROIdict):\n",
    "    distancearray = np.zeros(len(ROIdict))\n",
    "    for i in range(len(ROIdict)):\n",
    "        distancearray[i] = math.dist(XYPoint,ROIdict[i])\n",
    "    return np.argmin(distancearray)\n",
    "    \n",
    "def preprocess(F: np.ndarray, baseline: str, win_baseline: float, sig_baseline: float,\n",
    "               fs: float, prctile_baseline: float = 8) -> np.ndarray:\n",
    "    \"\"\" preprocesses fluorescence traces for spike deconvolution\n",
    "\n",
    "    baseline-subtraction with window \"win_baseline\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "\n",
    "    F : float, 2D array\n",
    "        size [neurons x time], in pipeline uses neuropil-subtracted fluorescence\n",
    "\n",
    "    baseline : str\n",
    "        setting that describes how to compute the baseline of each trace\n",
    "\n",
    "    win_baseline : float\n",
    "        window (in seconds) for max filter\n",
    "\n",
    "    sig_baseline : float\n",
    "        width of Gaussian filter in frames\n",
    "\n",
    "    fs : float\n",
    "        sampling rate per plane\n",
    "\n",
    "    prctile_baseline : float\n",
    "        percentile of trace to use as baseline if using `constant_prctile` for baseline\n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "\n",
    "    F : float, 2D array\n",
    "        size [neurons x time], baseline-corrected fluorescence\n",
    "\n",
    "    \"\"\"\n",
    "    win = int(win_baseline * fs)\n",
    "    if baseline == \"maximin\":\n",
    "        Flow = gaussian_filter(F, [sig_baseline])\n",
    "        Flow = minimum_filter1d(Flow, win)\n",
    "        Flow = maximum_filter1d(Flow, win)\n",
    "    elif baseline == \"constant\":\n",
    "        Flow = gaussian_filter(F, [sig_baseline])\n",
    "        Flow = np.amin(Flow)\n",
    "    elif baseline == \"constant_prctile\":\n",
    "        Flow = np.percentile(F, prctile_baseline, axis=1)\n",
    "        Flow = np.expand_dims(Flow, axis=1)\n",
    "    else:\n",
    "        Flow = 0.\n",
    "\n",
    "    F = F - Flow\n",
    "\n",
    "    return F\n",
    "    \n",
    "def indextonum(string):\n",
    "    indexarray = []\n",
    "    indices = string.split(',')\n",
    "    for i in range(len(indices)):\n",
    "        indexlist = indices[i].split('-')\n",
    "        for j in range(len(indexlist)):\n",
    "            index = int(indexlist[j])\n",
    "            indexarray = np.append(indexarray,index)\n",
    "    return indexarray\n",
    "    \n",
    "    \n",
    "def gettimedict(xmlfile):\n",
    "    xmlfirstlayer = pd.read_xml(xmlfile)\n",
    "    xmlsecondlayer = pd.read_xml(xmlfile, xpath='.//PVGalvoPointElement ')\n",
    "    tree = etree.parse(xmlfile)\n",
    "    xmlroot = str(etree.tostring(tree.getroot()))\n",
    "\n",
    "    timedict = {}\n",
    "    dictindex = 0\n",
    "    #[time on, time off, roi#, interpointdelay, duration,stim power\n",
    "\n",
    "    numiterations = xmlroot.split(' ')[1]\n",
    "    numiterations = int(numiterations.split('\"')[1])\n",
    "    iterationdelay = xmlroot.split(' ')[2]\n",
    "    iterationdelay = float(iterationdelay.split('\"')[1])\n",
    "\n",
    "\n",
    "    for j in range(numiterations):\n",
    "        for i in range(len(xmlfirstlayer)):\n",
    "            power = xmlfirstlayer['UncagingLaserPower'][i]\n",
    "            reps = xmlfirstlayer['Repetitions'][i]\n",
    "            if i== 0:\n",
    "                if j==0:\n",
    "                    starttime = xmlsecondlayer['InitialDelay'][0]  \n",
    "                else: \n",
    "                    starttime = xmlsecondlayer['InitialDelay'][0] + iterationdelay + timedict[dictindex-1][1]\n",
    "            else:\n",
    "                starttime = xmlsecondlayer['InitialDelay'][i] + timedict[dictindex-1][1] #the time off of the previous point\n",
    "            endtime = starttime + reps*(xmlsecondlayer['InterPointDelay'][i] + xmlsecondlayer['Duration'][i])\n",
    "            if type(xmlsecondlayer['Indices'][i]) == str:\n",
    "                indices = indextonum(xmlsecondlayer['Indices'][i])\n",
    "            else:\n",
    "                indices = [xmlsecondlayer['Indices'][i]]\n",
    "            timedict[dictindex] = [starttime,endtime,indices, xmlsecondlayer['InterPointDelay'][i],xmlsecondlayer['Duration'][i],power]\n",
    "            dictindex = dictindex + 1\n",
    "            \n",
    "    return timedict, numiterations, len(xmlfirstlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5cdc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Sequence\n",
    "from contextlib import contextmanager\n",
    "from tifffile import TiffWriter\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BinaryFile:\n",
    "\n",
    "    def __init__(self, Ly: int, Lx: int, filename: str, n_frames: int = None,\n",
    "                 dtype: str = \"int16\"):\n",
    "        \"\"\"\n",
    "        Creates/Opens a Suite2p BinaryFile for reading and/or writing image data that acts like numpy array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Ly: int\n",
    "            The height of each frame\n",
    "        Lx: int\n",
    "            The width of each frame\n",
    "        filename: str\n",
    "            The filename of the file to read from or write to\n",
    "        \"\"\"\n",
    "        self.Ly = Ly\n",
    "        self.Lx = Lx\n",
    "        self.filename = filename\n",
    "        self.dtype = dtype\n",
    "        write = (not os.path.exists(self.filename))\n",
    "\n",
    "        if write and n_frames is None:\n",
    "            raise ValueError(\n",
    "                \"need to provide number of frames n_frames when writing file\")\n",
    "        elif not write:\n",
    "            n_frames = self.n_frames\n",
    "        shape = (n_frames, self.Ly, self.Lx)\n",
    "        mode = \"w+\" if write else \"r+\"\n",
    "        self.file = np.memmap(self.filename, mode=mode, dtype=self.dtype, shape=shape)\n",
    "        self._index = 0\n",
    "        self._can_read = True\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_numpy_file_to_suite2p_binary(from_filename: str,\n",
    "                                             to_filename: str) -> None:\n",
    "        \"\"\"\n",
    "        Works with npz files, pickled npy files, etc.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        from_filename: str\n",
    "            The npy file to convert\n",
    "        to_filename: str\n",
    "            The binary file that will be created\n",
    "        \"\"\"\n",
    "        np.load(from_filename).tofile(to_filename)\n",
    "\n",
    "    @property\n",
    "    def nbytesread(self):\n",
    "        \"\"\"number of bytes per frame (FIXED for given file)\"\"\"\n",
    "        return np.int64(2 * self.Ly * self.Lx)\n",
    "\n",
    "    @property\n",
    "    def nbytes(self):\n",
    "        \"\"\"total number of bytes in the file.\"\"\"\n",
    "        return os.path.getsize(self.filename)\n",
    "\n",
    "    @property\n",
    "    def n_frames(self) -> int:\n",
    "        \"\"\"total number of frames in the file.\"\"\"\n",
    "        return int(self.nbytes // self.nbytesread)\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> Tuple[int, int, int]:\n",
    "        \"\"\"\n",
    "        The dimensions of the data in the file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        n_frames: int\n",
    "            The number of frames\n",
    "        Ly: int\n",
    "            The height of each frame\n",
    "        Lx: int\n",
    "            The width of each frame\n",
    "        \"\"\"\n",
    "        return self.n_frames, self.Ly, self.Lx\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of pixels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        size: int\n",
    "        \"\"\"\n",
    "        return np.prod(np.array(self.shape).astype(np.int64))\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"\n",
    "        Closes the file.\n",
    "        \"\"\"\n",
    "        self.file._mmap.close()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()\n",
    "\n",
    "    def __setitem__(self, *items):\n",
    "        indices, data = items\n",
    "        if data.dtype != \"int16\":\n",
    "            self.file[indices] = np.minimum(data, 2**15 - 2).astype(\"int16\")\n",
    "        else:\n",
    "            self.file[indices] = data\n",
    "\n",
    "    def __getitem__(self, *items):\n",
    "        indices, *crop = items\n",
    "        return self.file[indices]\n",
    "\n",
    "    def sampled_mean(self) -> float:\n",
    "        \"\"\"\n",
    "        Returns the sampled mean.\n",
    "        \"\"\"\n",
    "        n_frames = self.n_frames\n",
    "        nsamps = min(n_frames, 1000)\n",
    "        inds = np.linspace(0, n_frames, 1 + nsamps).astype(np.int64)[:-1]\n",
    "        frames = self.file[inds].astype(np.float32)\n",
    "        return frames.mean(axis=0)\n",
    "\n",
    "    @property\n",
    "    def data(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns all the frames in the file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        frames: n_frames x Ly x Lx\n",
    "            The frame data\n",
    "        \"\"\"\n",
    "        return self.file[:]\n",
    "\n",
    "    def bin_movie(self, bin_size: int, x_range: Optional[Tuple[int, int]] = None,\n",
    "                  y_range: Optional[Tuple[int, int]] = None,\n",
    "                  bad_frames: Optional[np.ndarray] = None,\n",
    "                  reject_threshold: float = 0.5) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns binned movie that rejects bad_frames (bool array) and crops to (y_range, x_range).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bin_size: int\n",
    "            The size of each bin\n",
    "        x_range: int, int\n",
    "            Crops the data to a minimum and maximum x range.\n",
    "        y_range: int, int\n",
    "            Crops the data to a minimum and maximum y range.\n",
    "        bad_frames: int array\n",
    "            The indices to *not* include.\n",
    "        reject_threshold: float\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        frames: nImg x Ly x Lx\n",
    "            The frames\n",
    "        \"\"\"\n",
    "\n",
    "        good_frames = ~bad_frames if bad_frames is not None else np.ones(\n",
    "            self.n_frames, dtype=bool)\n",
    "\n",
    "        batch_size = min(np.sum(good_frames), 500)\n",
    "        batches = []\n",
    "        for k in np.arange(0, self.n_frames, batch_size):\n",
    "            indices = slice(k, min(k + batch_size, self.n_frames))\n",
    "            data = self.file[indices]\n",
    "\n",
    "            if x_range is not None and y_range is not None:\n",
    "                data = data[:, slice(*y_range), slice(*x_range)]  # crop\n",
    "\n",
    "            good_indices = good_frames[indices]\n",
    "            if np.mean(good_indices) > reject_threshold:\n",
    "                data = data[good_indices]\n",
    "\n",
    "            if data.shape[0] > bin_size:\n",
    "                data = binned_mean(mov=data, bin_size=bin_size)\n",
    "                batches.extend(data)\n",
    "\n",
    "        mov = np.stack(batches)\n",
    "        return mov\n",
    "\n",
    "    def write_tiff(self, fname, range_dict={}):\n",
    "        \"Writes BinaryFile's contents using selected ranges from range_dict into a tiff file.\"\n",
    "        n_frames, Ly, Lx = self.shape\n",
    "        frame_range, y_range, x_range = (0,n_frames), (0, Ly), (0, Lx)\n",
    "        with TiffWriter(fname, bigtiff=True) as f:\n",
    "            # Iterate through current data and write each frame to a tiff\n",
    "            # All ranges should be Tuples(int,int)\n",
    "            if 'frame_range' in range_dict:\n",
    "                frame_range = range_dict['frame_range']\n",
    "            if 'x_range' in range_dict:\n",
    "                x_range = range_dict['x_range']\n",
    "            if 'y_range' in range_dict:\n",
    "                y_range = range_dict['y_range']\n",
    "            print('Frame Range: {}, y_range: {}, x_range{}'.format(frame_range, y_range, x_range))\n",
    "            for i in range(frame_range[0], frame_range[1]):\n",
    "                curr_frame = np.floor(self.file[i, y_range[0]:y_range[1], x_range[0]:x_range[1]]).astype(np.int16)\n",
    "                f.write(curr_frame)\n",
    "        print('Tiff has been saved to {}'.format(fname))\n",
    "\n",
    "def from_slice(s: slice) -> Optional[np.ndarray]:\n",
    "    \"\"\"Creates an np.arange() array from a Python slice object.  Helps provide numpy-like slicing interfaces.\"\"\"\n",
    "    return np.arange(s.start, s.stop, s.step) if any([s.start, s.stop, s.step\n",
    "                                                     ]) else None\n",
    "\n",
    "\n",
    "def binned_mean(mov: np.ndarray, bin_size) -> np.ndarray:\n",
    "    \"\"\"Returns an array with the mean of each time bin (of size \"bin_size\").\"\"\"\n",
    "    n_frames, Ly, Lx = mov.shape\n",
    "    mov = mov[:(n_frames // bin_size) * bin_size]\n",
    "    return mov.reshape(-1, bin_size, Ly, Lx).astype(np.float32).mean(axis=1)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def temporary_pointer(file):\n",
    "    \"\"\"context manager that resets file pointer location to its original place upon exit.\"\"\"\n",
    "    orig_pointer = file.tell()\n",
    "    yield file\n",
    "    file.seek(orig_pointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3650c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import maximum_filter1d, minimum_filter1d, gaussian_filter\n",
    "from lxml import etree\n",
    "import os\n",
    "\n",
    "nplane = 1\n",
    "reference_plane = 0\n",
    "directory = '/Users/rishachakraborty/Downloads/Tseries74xystim/'\n",
    "#stimtimedict, numiter, numstim, xmlfiletime, fluoresencedict, neuropildict, spikesdict, opsdict, databindict, statdict, stimcelldf, ROIdict = getdicts(directory, reference_plane)\n",
    "\n",
    "#optional iteration through files within directory\n",
    "#directory = '/Users/rishachakraborty/Downloads/XYSTIM/'\n",
    "#keyword = 'xystim'\n",
    "#files = [file for file in os.listdir(directory) if keyword in file]\n",
    "#for k in range(len(files)):\n",
    "    #directory = '/Users/rishachakraborty/Downloads/XYSTIM/' + files[k]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw total fluoresence, trace or dff across all frames\n",
    "\n",
    "fig,axs = plt.subplots(1,numstim, figsize=(20,4))\n",
    "for i in range(numstim):    \n",
    "    closestROIindex = closestROI([stimcelldf[i][1], stimcelldf[i][2]],ROIdict)\n",
    "    axs[i].plot(range(len(fluoresencedict[closestROIindex])), fluoresencedict[closestROIindex], alpha = 0.3)\n",
    "    trace  = gettrace(closestROIindex, fluoresencedict, opsdict, neuropildict)\n",
    "    axs[i].plot(range(len(trace)),trace)\n",
    "    dff = getdff(trace, opsdict)\n",
    "    axs[i].plot(range(len(dff)),dff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e42a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xystim\n",
    "\n",
    "#timearray: multiplicative factor = .067 for 4 frame averaging and .267 for 2 frame averaging\n",
    "\n",
    "tracestimavg = np.zeros(shape=(numstim,2,56))\n",
    "counter = 0\n",
    "frametimes = getframetimes((xmlfiletime['relativeTime']).to_numpy(),reference_plane,nplane)\n",
    "fig, axs = plt.subplots(1,numstim, figsize=(20,4))\n",
    "for i in range(len(stimtimedict)):\n",
    "    if counter == numstim:\n",
    "        counter = 0\n",
    "    stimframe = closestframe(((stimtimedict[i][0])/1000), frametimes)\n",
    "    startframe = closestframe(((stimtimedict[i][0])/1000) - 5, frametimes)\n",
    "    avgframe1 = closestframe(((stimtimedict[i][0])/1000) - 2.5, frametimes)\n",
    "    avgframe2 = closestframe(((stimtimedict[i][0])/1000) - 1.5, frametimes)\n",
    "    endframe = closestframe(((stimtimedict[i][0])/1000) + 10, frametimes)\n",
    "    timearray = [(frame - stimframe)*0.067 for frame in np.arange(startframe,endframe)]\n",
    "    roivalue = list({row for row in stimcelldf if stimcelldf[row][0] == stimtimedict[i][2][0]})\n",
    "    ROI = [stimcelldf[roivalue[0]][1],stimcelldf[roivalue[0]][2]]\n",
    "    closestROIindex = closestROI(ROI,ROIdict)\n",
    "    meanvalue = np.mean(fluoresencedict[closestROIindex][avgframe1:avgframe2])   \n",
    "    tracestim = fluoresencedict[closestROIindex][startframe:endframe]\n",
    "    tracestimadj = [(frame/meanvalue) for frame in tracestim]\n",
    "    axs[counter].plot(timearray,tracestimadj, alpha = 0.75)\n",
    "    #tracestimavg[counter,:] = tracestimavg[counter,:] + tracestim\n",
    "    counter = counter + 1\n",
    "#for i in range(numstim):\n",
    "#    axs[i].plot(np.arange(-30,30,1),tracestimavg[i,:]/numiter, color = 'black')\n",
    "#    axs[i].set(title = \"z = \" + str(round(stimcelldf[i][3], 3)))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average fluoresence of all stimmed ROIs across planes if multiplanestim\n",
    "avef = np.empty((nplane, opsdict['nframes'], len(stimcelldf)))\n",
    "avef[:] = np.nan\n",
    "\n",
    "for ip in range(nplane):\n",
    "    data = BinaryFile(Lx=opsdict['Lx'], Ly=opsdict['Ly'], filename= databindict[ip]).data    \n",
    "    for i in range(len(stimcelldf)):\n",
    "        avef[ip,:data.shape[0],i] = np.mean(data[:,statdict[closestROI([stimcelldf[i][1], stimcelldf[i][2]],ROIdict)]['ypix'],statdict[closestROI([stimcelldf[i][1], stimcelldf[i][2]],ROIdict)]['xpix']],1)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7b591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiplanestim\n",
    "\n",
    "\n",
    "meanarray = np.zeros(shape = (nplane,numstim,numiter))        \n",
    "\n",
    "for k in range(nplane):\n",
    "    fig, axs = plt.subplots(1,numstim, figsize=(20,4)) \n",
    "    frametimes = getframetimes((xmlfiletime['relativeTime']).to_numpy(),k,nplane)\n",
    "    counter = 0\n",
    "    for i in range(len(stimtimedict)):\n",
    "        if counter == numstim:\n",
    "            counter = 0\n",
    "        startframe = closestframe(((stimtimedict[i][0])/1000) - 5, frametimes)\n",
    "        endframe = closestframe(((stimtimedict[i][0])/1000) + 10, frametimes)\n",
    "        stimframe = closestframe(((stimtimedict[i][0])/1000),frametimes)\n",
    "        meanarray[k,counter,int(i/numstim)] = np.mean(avef[k,startframe:stimframe,counter])   \n",
    "        tracestim = avef[k,startframe:endframe,counter]\n",
    "        \n",
    "        for j in range(len(stimtimedict[i][2])):\n",
    "            roivalue = list({row for row in stimcelldict if stimcelldict[row][0] == stimtimedict[i][2][j]})\n",
    "            ROI = stimcelldict[roivalue[0]][1]\n",
    "            closestROIindex = closestROI(ROI,ROIdict)\n",
    "            trace  = fluoresencedict[closestROIindex] - opsdict['neucoeff']*neuropildict[closestROIindex]\n",
    "            tracestim = trace[startframe:endframe]\n",
    "            tracestim = fluoresencedict[closestROIindex][startframe:endframe]\n",
    "        axs[counter].plot(np.arange(-5,10,15/len(tracestim)),tracestim)\n",
    "        counter = counter + 1\n",
    "    \n",
    "meanofmeans = np.mean(meanarray,axis=2)\n",
    "stdofmeans = np.std(meanarray,axis=2)\n",
    "\n",
    "fig2,axs2 = plt.subplots(1,nplane, figsize=(20,4)) \n",
    "\n",
    "for i in range(nplane):\n",
    "    fig, axs1 = plt.subplots(1,numstim, figsize=(20,4)) \n",
    "    frametimes = getframetimes((xmlfiletime['relativeTime']).to_numpy(),i,nplane)\n",
    "    counter = 0\n",
    "    for j in range(len(stimtimedict)):\n",
    "        if counter == numstim:\n",
    "            counter = 0\n",
    "        startframe = closestframe(((stimtimedict[j][0])/1000) - 5, frametimes)\n",
    "        endframe = closestframe(((stimtimedict[j][0])/1000) + 10, frametimes)\n",
    "        zfluor = np.zeros(shape = [numiter,endframe-startframe])\n",
    "        trace = avef[i,startframe:endframe,counter]\n",
    "        k = int(j/numstim)\n",
    "        zfluor[k] = [(frame - meanofmeans[i,counter])/stdofmeans[i,counter] for frame in trace]\n",
    "        axs1[counter].plot(np.arange(-5,10,15/len(zfluor[k])),zfluor[k])\n",
    "        axs2[i].plot(np.arange(-5,10,15/len(np.mean(zfluor,axis=0))),np.mean(zfluor,axis=0))\n",
    "        counter = counter + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
